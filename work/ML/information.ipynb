{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definitions, thoughts and everything else"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "- [Machine Learning models](#section1)\n",
    "- [Target Variables](#section2)\n",
    "- [Regression vs. Classification](#section3)\n",
    "- [Model Choices Based on Target Variable](#section4)\n",
    "  - [Binary Target Variable (Classification)](#subsection4-1)\n",
    "  - [Count Target Variable (Regression)](#subsection4-2)\n",
    "  - [Percentage Target Variable (Regression)](#subsection4-3)\n",
    "- [Metrics](#section5)\n",
    "- [Models Tried](#section6)\n",
    "  - [Random Forest Classifier with binary Target](#subsection6-1)\n",
    "    - [Key Findings](#subsection6-1-1)\n",
    "    - [Results](#subsection6-1-2)\n",
    "  - [Random Forest Classifier with binary Target](#subsection6-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section1\"></a>\n",
    "## Machine Learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "Machine Learning\n",
    "  ├── Supervised Learning\n",
    "  │    ├── Regression\n",
    "  │    │    ├── Linear Regression (LR)\n",
    "  │    │    └── Generalized Linear Models (GLM)\n",
    "  │    ├── Classification\n",
    "  │    │    ├── Logistic Regression (LogR)\n",
    "  │    │    └── Support Vector Machines (SVM)\n",
    "  │    ├── Generative Learning\n",
    "  │    │    ├── Gaussian Discriminant Analysis (GDA)\n",
    "  │    │    └── Naive Bayes (NB)\n",
    "  │    ├── Tree-based and Ensemble Methods\n",
    "  │    │    ├── CART\n",
    "  │    │    ├── Random Forest (RF)\n",
    "  │    │    └── Boosting\n",
    "  │    └── Other Non-parametric Approaches\n",
    "  │         └── k-Nearest Neighbors (k-NN)\n",
    "  ├── Unsupervised Learning\n",
    "  │    ├── Clustering\n",
    "  │    │    ├── k-means\n",
    "  │    │    ├── Hierarchical Clustering\n",
    "  │    │    └── Expectation-Maximization (EM)\n",
    "  │    └── Dimension Reduction\n",
    "  │         ├── Principal Component Analysis (PCA)\n",
    "  │         └── Independent Component Analysis (ICA)\n",
    "  ├── Deep Learning\n",
    "  │    ├── Neural Networks (NN)\n",
    "  │    ├── Convolutional Neural Networks (CNN)\n",
    "  │    └── Recurrent Neural Networks (RNN)\n",
    "  └── Reinforcement Learning and Control\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Process Summary\n",
    "\n",
    "- Data Preparation: Normalize and split your data.\n",
    "\n",
    "- Model Definition: Define your LSTM model architecture.\n",
    "\n",
    "- Hyperparameter Tuning: Use methods like Grid Search, Random Search, or manual tuning.\n",
    "\n",
    "- Model Training: Train your model with training data and validate with validation data.\n",
    "\n",
    "- Model Evaluation: Evaluate the model on test data using appropriate metrics.\n",
    "\n",
    "- Cross-Validation: Ensure robustness with K-fold cross-validation.\n",
    "\n",
    "- Advanced Tuning: Consider advanced hyperparameter optimization libraries.\n",
    "\n",
    "- Model Persistence: Save and load your trained model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section2\"></a>\n",
    "## Target Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section3\"></a>\n",
    "### Regression vs. Classification\n",
    "\n",
    "The primary distinction between regression and classification problems lies in the nature of the target variable.\n",
    "\n",
    "**Regression:** Predicts a continuous numerical value.\n",
    "\n",
    "Example: Predicting the price of a house, temperature, or in your case, the count of available docks or the percentage of docking availability.\n",
    "\n",
    "**Classification**: Predicts a categorical value or class.\n",
    "\n",
    "Example: Classifying an email as spam or not spam, predicting whether a customer will churn, or in your case, predicting whether there are any available docks (binary classification)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section4\"></a>\n",
    "## Model Choices Based on Target Variable\n",
    "\n",
    "<a id=\"subsection4-1\"></a>\n",
    "### Binary Target Variable (Classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Logistic Regression:** Often the starting point for binary classification.\n",
    "\n",
    "* **Decision Trees:** Can handle non-linear relationships and provide interpretable models.\n",
    "\n",
    "* **Random Forest:** An ensemble of decision trees, often providing better performance than individual trees.\n",
    "\n",
    "* **Support Vector Machines (SVM):** Effective for complex classification problems.\n",
    "\n",
    "* **Naive Bayes:** Simple and efficient, especially for text classification but can also be used for numerical data.\n",
    " \n",
    "* **Neural Networks:** Powerful but require more data and computational resources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"subsection4-2\"></a>\n",
    "### Count Target Variable (Regression)\n",
    "\n",
    "* **Linear Regression:** Suitable for linear relationships between features and the target.\n",
    "\n",
    "* **Decision Trees:** Can handle non-linear relationships but might not be as accurate as specialized regression models.\n",
    "\n",
    "* **Random Forest:** Often performs well for regression tasks.\n",
    "\n",
    "* **Gradient Boosting Machines (GBM):** Known for their strong performance in regression problems.\n",
    "\n",
    "* **Support Vector Regression (SVR):** An extension of SVM for regression.\n",
    "\n",
    "* **Neural Networks:** Can be used for regression but require careful architecture design."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"subsection4-3\"></a>\n",
    "### Percentage Target Variable (Regression)\n",
    "\n",
    "* **Linear Regression:** Can be a starting point, but consider transformations if the data is not normally distributed.\n",
    "\n",
    "* **Decision Trees, Random Forest, GBM:** These models can handle non-linear relationships and often perform well for percentage-based predictions.\n",
    "\n",
    "* **Beta Regression:** Specifically designed for modeling data constrained between 0 and 1, which is suitable for percentages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section5\"></a>\n",
    "## Metrics\n",
    "\n",
    "<a id=\"subsection5-1\"></a>\n",
    "### Depends on the target variable (like everything)\n",
    "\n",
    "* **Binary:** Accuracy, precision, recall, F1-score, ROC curve, AUC.\n",
    "* **Count or percentage:** Mean Squared Error (MSE), Mean Absolute Error (MAE), Root Mean Squared Error (RMSE), R-squared."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section6\"></a>\n",
    "## Models Tried\n",
    "\n",
    "<a id=\"subsection6-1\"></a>\n",
    "### Random Forest Classifier with binary Target\n",
    "<a id=\"subsection6-1-1\"></a>\n",
    "#### Key Findings\n",
    "\n",
    "* It takes forever to train the model with all the stations 510+\n",
    "\n",
    "* Took only 5 stations\n",
    "\n",
    "* Class inbalance, predicts well the True but it only has a 61% for False (No Docking available)\n",
    "\n",
    "* useless fields: is_holiday, disctrict\n",
    "\n",
    "* GridSearch: First took 7.5 hours and did not improved much, now it takes more than 2 hours\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"subsection6-1-2\"></a>\n",
    "#### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Removed month and day\n",
    "\n",
    "```\n",
    "Accuracy: 0.8513997424544444\n",
    "Confusion Matrix:\n",
    " [[ 1256  7452]\n",
    " [  972 47009]]\n",
    "Classification Report:\n",
    "               precision    recall  f1-score   support\n",
    "\n",
    "       False       0.56      0.14      0.23      8708\n",
    "        True       0.86      0.98      0.92     47981\n",
    "\n",
    "    accuracy                           0.85     56689\n",
    "   macro avg       0.71      0.56      0.57     56689\n",
    "weighted avg       0.82      0.85      0.81     56689\n",
    "\n",
    "Precision:  0.8631681386680377\n",
    "Recall:  0.9797419812008921\n",
    "F1 Score:  0.917768102926534\n",
    "ROC AUC:  0.5619885836183606\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* adding Month\n",
    "\n",
    "```\n",
    "Accuracy: 0.8555980878124504\n",
    "Confusion Matrix:\n",
    " [[ 1470  7238]\n",
    " [  948 47033]]\n",
    "Classification Report:\n",
    "               precision    recall  f1-score   support\n",
    "\n",
    "       False       0.61      0.17      0.26      8708\n",
    "        True       0.87      0.98      0.92     47981\n",
    "\n",
    "    accuracy                           0.86     56689\n",
    "   macro avg       0.74      0.57      0.59     56689\n",
    "weighted avg       0.83      0.86      0.82     56689\n",
    "\n",
    "Precision:  0.8666322713788212\n",
    "Recall:  0.9802421791959317\n",
    "F1 Score:  0.9199428862027149\n",
    "ROC AUC:  0.5745262342924996\n",
    "```\n",
    "* Month and day\n",
    "```\n",
    "Accuracy: 0.8624600892589391\n",
    "Confusion Matrix:\n",
    " [[ 1793  6915]\n",
    " [  882 47099]]\n",
    "Classification Report:\n",
    "               precision    recall  f1-score   support\n",
    "\n",
    "       False       0.67      0.21      0.32      8708\n",
    "        True       0.87      0.98      0.92     47981\n",
    "\n",
    "    accuracy                           0.86     56689\n",
    "   macro avg       0.77      0.59      0.62     56689\n",
    "weighted avg       0.84      0.86      0.83     56689\n",
    "\n",
    "Precision:  0.871977635427852\n",
    "Recall:  0.9816177236822909\n",
    "F1 Score:  0.923555076229227\n",
    "ROC AUC:  0.5937601709821653\n",
    "```\n",
    "* Month and day as numerical\n",
    "```\n",
    "Accuracy: 0.8609430400959622\n",
    "Confusion Matrix:\n",
    " [[ 1895  6813]\n",
    " [ 1070 46911]]\n",
    "Classification Report:\n",
    "               precision    recall  f1-score   support\n",
    "\n",
    "       False       0.64      0.22      0.32      8708\n",
    "        True       0.87      0.98      0.92     47981\n",
    "\n",
    "    accuracy                           0.86     56689\n",
    "   macro avg       0.76      0.60      0.62     56689\n",
    "weighted avg       0.84      0.86      0.83     56689\n",
    "\n",
    "Precision:  0.8731851686397141\n",
    "Recall:  0.9776995060544799\n",
    "F1 Score:  0.9224915195909739\n",
    "ROC AUC:  0.5976577456776763\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"subsection6-2\"></a>\n",
    "### Random Forest Regressor with percentage Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
